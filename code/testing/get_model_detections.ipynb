{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 17:41:05.850687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-06 17:41:17.278669: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-02-06 17:41:17.282586: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-06 17:41:17.282672: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-06 17:41:17.283043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cdr845.int.cedar.computecanada.ca): /proc/driver/nvidia/version does not exist\n",
      "2022-02-06 17:41:17.285245: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-06 17:41:17.285408: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from ketos.audio.audio_loader import  AudioFrameLoader, FrameStepper, audio_repres_dict\n",
    "from ketos.neural_networks import load_model_file\n",
    "from ketos.neural_networks.resnet import ResNetInterface\n",
    "from ketos.neural_networks.dev_utils.detection import process, process_audio_loader, save_detections, merge_overlapping_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='../../trained_models/kw_multi_detector_v03_3class.kt'\n",
    "output_file_short_note='_v03_3class_' # add anything here to add in the name of the detections file! By default keep it an empty string\n",
    "annot_file_path='../../annotations/test/' # Path where test annotations are stored\n",
    "detection_file_path='../../model_detections/'\n",
    "test_file_list='../../file_lists/test/'\n",
    "audio_storage_root_path='/home/sadman/projects/ctb-ruthjoy/SRKW/'\n",
    "\n",
    "num_segs=128\n",
    "step_size=None\n",
    "buffer=0.0\n",
    "win_len=1\n",
    "threshold=0.0\n",
    "group=False\n",
    "progress_bar=True\n",
    "merge=False\n",
    "\n",
    "save_detections_flag=True\n",
    "save_all_performance_flag=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 5.0,\n",
       " 'rate': 10000,\n",
       " 'window': 0.051,\n",
       " 'step': 0.01955,\n",
       " 'freq_min': 0,\n",
       " 'freq_max': 6000,\n",
       " 'window_func': 'hamming',\n",
       " 'normalize_wav': True,\n",
       " 'type': 'MagSpectrogram',\n",
       " 'transforms': [{'name': 'reduce_tonal_noise'},\n",
       "  {'name': 'normalize', 'mean': 0.0, 'std': 1.0}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the classifier and the spectrogram parameters\n",
    "model, audio_repr = load_model_file(model, './tmp_folder', load_audio_repr=True)\n",
    "spec_config = audio_repr[0]['spectrogram']\n",
    "spec_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_data, batch_support_data, model, buffer=0, step=0.5, spec_dur=3.0, threshold=0.5, win_len=1, group=False):\n",
    "    \"\"\" Runs one batch of (overlapping) spectrogram throught the classifier.\n",
    "\n",
    "        Args:\n",
    "            batch_data: numpy array\n",
    "                An array with shape n,f,t,  where n is the number of spectrograms in the batch, t is the number of time bins and f the number of frequency bins.\n",
    "            batch_support_data: numpy array\n",
    "                An array of shape n x 2, where n is the batch size. The second dimension contains the filename and the start timestamp for each input in the batch\n",
    "            model: ketos model\n",
    "                The ketos trained classifier\n",
    "            buffer: float\n",
    "                Time (in seconds) to be added around the detection\n",
    "            step: float\n",
    "                The time interval(in seconds) between the starts of each contiguous input spectrogram.\n",
    "                For example, a step=0.5 indicates that the first spectrogram starts at time 0.0s (from the beginning of the audio file), the second at 0.5s, etc.\n",
    "            spec_dur: float\n",
    "                The duration of each input spectrogram in seconds\n",
    "            threshold: float or list of floats\n",
    "                Minimum score value for a time step to be considered as a detection.\n",
    "            win_len:int\n",
    "                The windown length for the moving average. Must be an odd integer. The default value is 5.\n",
    "            group:bool\n",
    "                If False, return the filename, start, duration and scores for each spectrogram with score above the threshold. In this case, the duration will always be the duration of a single spectrogram.\n",
    "                If True (default), average scores over(overlapping) spectrograms and group detections that are immediatelly next to each other. In this case, the score given for that detection will be the\n",
    "                average score of all spectrograms comprising the detection event.\n",
    "\n",
    "        Returns:\n",
    "            batch_detections: list\n",
    "                An array with all the detections in the batch. Each detection (first dimension) consists of the filename, start, duration and score.\n",
    "                The start is given in seconds from the beginning of the file and the duration in seconds. \n",
    "                If a list of threshold values is specified, the returned object will be a list of arrays with len(batch_detections) = len(thresholds)         \n",
    "\n",
    "    \"\"\"\n",
    "    thresholds = threshold if isinstance(threshold, list) else [threshold]\n",
    "\n",
    "    probability_scores = model.run_on_batch(batch_data, return_raw_output=True)\n",
    "    class_index = np.argmax(np.array(probability_scores), axis=1)\n",
    "    # label_to_text_mapping={0: 'OTHER', 1: 'KW', 2: 'HB', 3: 'D'}\n",
    "\n",
    "    if win_len == 1:\n",
    "        scores = probability_scores[:,1]\n",
    "    else:\n",
    "        scores = compute_avg_score(probability_scores[:,1], win_len=win_len)\n",
    "        \n",
    "    if group == True:\n",
    "        batch_detections = group_detections(scores, batch_support_data, buffer=buffer, step=step, spec_dur=spec_dur, threshold=thresholds) \n",
    "\n",
    "    else:\n",
    "        batch_detections = []\n",
    "\n",
    "        for thres in thresholds:\n",
    "            threshold_indices = scores >= thres\n",
    "            batch_det = np.vstack([batch_support_data[threshold_indices,0], batch_support_data[threshold_indices,1], np.repeat(spec_dur, sum(threshold_indices)), scores[threshold_indices]])\n",
    "            if batch_det.shape[1] == 0:\n",
    "                batch_det = []\n",
    "            else:\n",
    "                batch_det = [(batch_det.T[det_index][0], \n",
    "                              float(batch_det.T[det_index][1]), \n",
    "                              float(batch_det.T[det_index][2]), \n",
    "                              float(batch_det.T[det_index][3]), \n",
    "                              int(class_index[det_index])) for det_index in range(len(batch_det.T))]\n",
    "\n",
    "            batch_detections.append(batch_det)\n",
    "\n",
    "    if not isinstance(threshold, list): \n",
    "        batch_detections = batch_detections[0]\n",
    "        \n",
    "    return batch_detections\n",
    "\n",
    "def process_audio_loader(audio_loader, model, batch_size=128, threshold=0.5, buffer=0, win_len=1, group=False, progress_bar=False, merge=False):\n",
    "    \"\"\" Use an audio_loader object to compute spectrogram from the audio files and process them with the trained classifier.\n",
    "\n",
    "        Args:\n",
    "            audio_loader: a ketos.audio.audio_loader.AudioFrameLoader object\n",
    "                An audio loader that computes spectrograms from the audio audio files as requested\n",
    "            model: ketos model\n",
    "                The ketos trained classifier\n",
    "            batch_size:int\n",
    "                The number of spectrogram to process at a time.\n",
    "            threshold: float or list of floats\n",
    "                Minimum score value for a time step to be considered as a detection.\n",
    "            buffer: float\n",
    "                Time (in seconds) to be added around the detection\n",
    "            win_len:int\n",
    "                The windown length for the moving average. Must be an odd integer. The default value is 5.   \n",
    "            group:bool\n",
    "                If False, return the filename, start, duration and scores for each spectrogram with score above the threshold. In this case, the duration will always be the duration of a single spectrogram.\n",
    "                If True (default), average scores over(overlapping) spectrograms and group detections that are immediatelly next to each other. In this case, the score given for that detection will be the\n",
    "                average score of all spectrograms comprising the detection event.\n",
    "            progress_bar: bool\n",
    "                Show progress bar.  \n",
    "            merge: bool\n",
    "                Apply :func:`merge_overlapping_detections` to the detections before they are returned. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            detections: list\n",
    "                List of detections.\n",
    "                If a list of threshold values is specified, the returned object will be a list of lists with len(detections) = len(thresholds)         \n",
    "    \"\"\"\n",
    "    assert isinstance(win_len, int) and win_len%2 == 1, 'win_len must be an odd integer'\n",
    "\n",
    "    thresholds = threshold if isinstance(threshold, list) else [threshold]\n",
    "        \n",
    "    n_extend = int((win_len - 1) / 2)\n",
    "\n",
    "    n_batches = audio_loader.num() // batch_size\n",
    "    last_batch_size = batch_size + (audio_loader.num() % batch_size)\n",
    "\n",
    "    if n_batches == 0: \n",
    "        batch_sizes = [audio_loader.num()]\n",
    "    elif n_batches == 1:\n",
    "        batch_sizes = [last_batch_size]\n",
    "    else:\n",
    "        batch_sizes = [batch_size + n_extend] + [batch_size + 2 * n_extend for _ in range(n_batches - 2)] + [last_batch_size + n_extend]\n",
    "\n",
    "    detections = [[] for _ in range(len(thresholds))]\n",
    "    specs_prev_batch = []\n",
    "    duration = None\n",
    "    step = 0\n",
    "\n",
    "    for siz in tqdm(batch_sizes, disable = not progress_bar): \n",
    "        batch_data, batch_support_data = [], []\n",
    "\n",
    "        # first, collect data from the last specs from previous batch, if any            \n",
    "        for spec in specs_prev_batch: \n",
    "            batch_data.append(spec.data)\n",
    "            support_data = (spec.filename, spec.offset)\n",
    "            batch_support_data.append(support_data)\n",
    "            duration = spec.duration()\n",
    "\n",
    "        # then, load specs from present batch\n",
    "        specs_prev_batch = []\n",
    "        while len(batch_data) < siz:\n",
    "            spec = next(audio_loader)\n",
    "            batch_data.append(spec.data)\n",
    "            support_data = (spec.filename, spec.offset)\n",
    "            batch_support_data.append(support_data)\n",
    "            if siz - len(batch_data) < 2 * n_extend: specs_prev_batch.append(spec) # store last few specs\n",
    "            duration = spec.duration()\n",
    "\n",
    "        if len(batch_support_data) >= 2:\n",
    "            step = batch_support_data[1][1] - batch_support_data[0][1]\n",
    "\n",
    "        if step <= 0: step = duration\n",
    "\n",
    "        batch_support_data = np.array(batch_support_data)\n",
    "        batch_data = np.array(batch_data)\n",
    "\n",
    "        batch_detections = process_batch(batch_data=batch_data, batch_support_data=batch_support_data, model=model, threshold=thresholds, \n",
    "                                        buffer=buffer, step=step, spec_dur=duration, win_len=win_len, group=group)\n",
    "\n",
    "        for i in range(len(thresholds)):\n",
    "            if len(batch_detections[i]) > 0: detections[i] += batch_detections[i]\n",
    "\n",
    "    if merge:\n",
    "        for i in range(len(thresholds)):\n",
    "            detections[i] = merge_overlapping_detections(detections[i])\n",
    "\n",
    "    if not isinstance(threshold, list): \n",
    "        detections = detections[0]\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_detections(detections, save_to):\n",
    "    \"\"\" Save the detections to a csv file\n",
    "\n",
    "        Args:\n",
    "            detections: numpy.array\n",
    "                List of detections\n",
    "            save_to:string\n",
    "                The path to the .csv file where the detections will be saved.\n",
    "                Example: \"/home/user/detections.csv\"\n",
    "    \"\"\"\n",
    "    if len(detections) == 0: return\n",
    "\n",
    "    a = np.array(detections)\n",
    "    df = pd.DataFrame({'filename':a[:,0], 'start':a[:,1], 'duration':a[:,2], 'predicted_label':a[:,4]})\n",
    "    include_header = not os.path.exists(save_to)\n",
    "    df.to_csv(save_to, mode='a', index=False, header=include_header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_files(dataframe):\n",
    "    \"\"\" Save the detections to a csv file\n",
    "\n",
    "        Args:\n",
    "            dataframe: pandas.DataFrame\n",
    "                List of files for testing a detector\n",
    "                \n",
    "        Returns: \n",
    "            : pandas.DataFrame\n",
    "                Filtered dataframe after removing the files that do not exist\n",
    "    \"\"\"\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if(os.path.isfile(row['filename'])==False):\n",
    "            print(row['filename'], \" not found\")\n",
    "            dataframe = dataframe.drop([index])\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files BEFORE removing missing files: 22\n",
      "Number of files AFTER removing missing files: 22\n",
      "file_name orcasound.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]2022-02-06 17:42:35.526901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-02-06 17:42:35.556166: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2095105000 Hz\n",
      "100%|██████████| 4/4 [02:15<00:00, 33.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634 detections saved to ../../model_detections/detections_orcasound.csv\n",
      "Number of files BEFORE removing missing files: 133\n",
      "Number of files AFTER removing missing files: 133\n",
      "file_name superpod_lime_kiln.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [11:38<00:00, 58.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646 detections saved to ../../model_detections/detections_superpod_lime_kiln.csv\n",
      "Number of files BEFORE removing missing files: 42\n",
      "Number of files AFTER removing missing files: 42\n",
      "file_name jasco_roberts_bank.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [09:15<00:00, 29.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520 detections saved to ../../model_detections/detections_jasco_roberts_bank.csv\n",
      "Number of files BEFORE removing missing files: 748\n",
      "Number of files AFTER removing missing files: 748\n",
      "file_name onc_barkley_canyon_test_multiclass.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [2:24:17<00:00, 24.74s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44826 detections saved to ../../model_detections/detections_onc_barkley_canyon_test_multiclass.csv\n",
      "Number of files BEFORE removing missing files: 5\n",
      "Number of files AFTER removing missing files: 5\n",
      "file_name jasco_boundary_pass.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [07:37<00:00, 32.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 detections saved to ../../model_detections/detections_jasco_boundary_pass.csv\n",
      "Number of files BEFORE removing missing files: 73\n",
      "Number of files AFTER removing missing files: 73\n",
      "file_name onc_barkley_canyon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [14:52<00:00, 26.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4380 detections saved to ../../model_detections/detections_onc_barkley_canyon.csv\n"
     ]
    }
   ],
   "source": [
    "all_results_df=pd.DataFrame(columns=['dataset', \n",
    "                                     'accuracy', \n",
    "                                     'precision', \n",
    "                                     'recall', \n",
    "                                     'false_positive_rate', \n",
    "                                     'confusion_matrix'])\n",
    "\n",
    "# load each test file and do all the calculations on them\n",
    "if test_file_list is not None:\n",
    "    for file_path in glob.glob(test_file_list+'*.csv'):\n",
    "        file_list = pd.read_csv(file_path)\n",
    "        \n",
    "        # appending audio folder location to each file name\n",
    "        file_list['filename'] = audio_storage_root_path + file_list['filename'].astype(str)\n",
    "\n",
    "        print(\"Number of files BEFORE removing missing files:\", len(file_list))\n",
    "        # Make sure each file actually exists in the cedar, if not, then remove from dataframe\n",
    "        file_list = remove_missing_files(file_list)\n",
    "        print(\"Number of files AFTER removing missing files:\", len(file_list))\n",
    "\n",
    "        file_list = list(file_list['filename'])\n",
    "        \n",
    "        # extract the audio folder path\n",
    "        last_index_of_slash=file_list[0].rindex('/')\n",
    "        audio_folder=file_list[0][0:last_index_of_slash]\n",
    "        \n",
    "        # extract the file name from the folder path in the format of \"filename.csv\"\n",
    "        file_name=file_path[file_path.rindex('/')+1:len(file_path)]\n",
    "        print(\"file_name\", file_name)\n",
    "        \n",
    "        # initialize the audio loader\n",
    "        audio_loader = AudioFrameLoader(frame=spec_config['duration'], \n",
    "                                        step=step_size, \n",
    "                                        path=audio_folder, \n",
    "                                        filename=file_list, \n",
    "                                        repres=spec_config)\n",
    "\n",
    "        # get the detection scores\n",
    "        detections = process_audio_loader(audio_loader, \n",
    "                                          model=model, \n",
    "                                          batch_size=num_segs, \n",
    "                                          buffer=buffer, \n",
    "                                          threshold=threshold, \n",
    "                                          group=group, \n",
    "                                          win_len=win_len, \n",
    "                                          progress_bar=progress_bar,\n",
    "                                          merge=merge)\n",
    "            \n",
    "        if save_detections_flag == True:\n",
    "            # get the output file name\n",
    "            output=detection_file_path+\"detections_\"+file_name\n",
    "                \n",
    "            # save the each detections on test dataset\n",
    "            if os.path.isfile(output): os.remove(output) #remove, if already exists\n",
    "            print(f'{len(detections)} detections saved to {output}')\n",
    "            detections_df=save_detections(detections=detections, save_to=output)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b96e40ceac2b3ccede4ea89bd6ac2d6ffadd65bc309d45cf8a3ec91823663213"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
