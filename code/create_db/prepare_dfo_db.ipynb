{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ketos.data_handling import selection_table as sl\n",
    "from ketos.data_handling.database_interface import AudioWriter, create_database\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "import ketos.audio.audio_loader as al\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path='/home/sadmans/KW_detector_multiclass/' # Orca-VM\n",
    "# root_path='/home/sadman/KW_detector_multiclass/' # DL Training pc\n",
    "# root_path='/home/sadman/projects/ctb-ruthjoy/sadman/Projects/KW_detector_multiclass/' # Cedar\n",
    "root_path='../../' \n",
    "cedar_username='sadman'\n",
    "\n",
    "spec_cfg = load_audio_representation(root_path+'code/create_db/spec_config.json', name=\"spectrogram\")\n",
    "print(\"spec_cfg:\", spec_cfg)\n",
    "\n",
    "path_dict = {'train_annot': root_path+'annotations/train/',\n",
    "             'test_annot': root_path+'annotations/test/',\n",
    "             'audio_data_dir': '/data/audio',\n",
    "             'database_save_filename': root_path+'saved_database/test_ds_multiclass_original.h5'\n",
    "             }\n",
    "\n",
    "select_step, select_min_overlap=spec_cfg['duration'], 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DFO annotation\n",
    "dataset_name='dfo_no_overlap'\n",
    "annot_df=pd.read_csv(path_dict['train_annot']+dataset_name+'_train_multiclass.csv', sep=',')\n",
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stanradize annotation\n",
    "std_annot_df, label_dict=sl.standardize(table=annot_df, signal_labels=['KW', 'HB', 'D', 'OTHER'], trim_table=False, return_label_dict=True)\n",
    "print(\"label_dict:\", label_dict) # {'KW': 1, 'HB': 2, 'D': 3}\n",
    "\n",
    "sel_annot_df = sl.select(annotations=std_annot_df, length=spec_cfg['duration'], step=select_step, min_overlap=select_min_overlap, center=False)\n",
    "kw_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=1, start=None, end=None)\n",
    "hb_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=2, start=None, end=None)\n",
    "d_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=3, start=None, end=None)\n",
    "other_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=4, start=None, end=None)\n",
    "print(len(kw_sel_annot_df), len(hb_sel_annot_df), len(d_sel_annot_df), len(other_sel_annot_df))\n",
    "print(\"Adding positive samples from \", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read audio files from tar file\n",
    "tar = tarfile.open('/home/'+cedar_username+'/projects/ctb-ruthjoy/SRKW/DFO/DFO.tar')\n",
    "all_tar_names=tar.getnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_database(output_file, data_dir, selections, channel=0, \n",
    "    audio_repres={'type': 'Waveform'}, annotations=None, dataset_name=None,\n",
    "    max_size=None, verbose=True, progress_bar=True, discard_wrong_shape=False, \n",
    "    allow_resizing=1, include_source=True, include_label=True, \n",
    "    include_attrs=False, attrs=None, data_name=None, index_cols=None,\n",
    "    mode='a', tar_file=None, tar_extract_location=root_path+'saved_database/'):\n",
    "\n",
    "    \"\"\" Create a database from a selection table where audio files are saved within a .tar file\n",
    "\n",
    "        If 'dataset_name' is not specified, the name of the folder containing the audio \n",
    "        files ('data_dir') will be used.\n",
    "        \n",
    "        If the method encounters problems loading/writing a sound clipe, it continues \n",
    "        while printing a warning\n",
    "    \n",
    "        Args:\n",
    "            output_file:str\n",
    "                The name of the HDF5 file in which the data will be stored.\n",
    "                Can include the path (e.g.:'/home/user/data/database_abc.h5').\n",
    "                If the file does not exist, it will be created.\n",
    "                If the file already exists, new data will be appended to it.\n",
    "            data_dir:str\n",
    "                Path to folder containing \\*.wav files.\n",
    "            selections: pandas DataFrame\n",
    "                Selection table\n",
    "            channel: int\n",
    "                For stereo recordings, this can be used to select which channel to read from\n",
    "            audio_repres: dict or list(dict)\n",
    "                A dictionary containing the parameters used to generate the spectrogram or waveform\n",
    "                segments. See :class:~ketos.audio.auio_loader.AudioLoader for details on the \n",
    "                required and optional fields for each type of signal. It is also possible to specify \n",
    "                multiple audio representations as a list.\n",
    "            annotations: pandas DataFrame\n",
    "                Annotation table. Optional.\n",
    "            dataset_name:str\n",
    "                Name of the node (HDF5 group) within the database (e.g.: 'train')\n",
    "                Under this node, two datasets will be created: 'data' and 'data_annot',\n",
    "                containing the data (spectrograms or waveforms) and the annotations for each\n",
    "                entry in the selections_table.                \n",
    "            max_size: int\n",
    "                Maximum size of output database file in bytes.\n",
    "                If file exceeds this size, it will be split up into several \n",
    "                files with _000, _001, etc, appended to the filename.\n",
    "                The default values is max_size=1E9 (1 Gbyte). \n",
    "                If None, no restriction is imposed on the file size (i.e. the file \n",
    "                is never split).\n",
    "            verbose: bool\n",
    "                Print relevant information during execution such as no. of files written to disk\n",
    "            progress_bar: bool\n",
    "                Show progress bar.  \n",
    "            discard_wrong_shape: bool\n",
    "                Discard objects that do not have the same shape as previously saved objects. Default is False.\n",
    "            allow_resizing: int\n",
    "                If the object shape differs from previously saved objects, the object \n",
    "                will be resized using the resize method of the scikit-image package, provided the mismatch \n",
    "                is no greater than allow_resizing in either dimension. \n",
    "            include_source: bool\n",
    "                If True, the name of the wav file from which the waveform or \n",
    "                spectrogram was generated and the offset within that file, is \n",
    "                saved to the table. Default is True.\n",
    "            include_label: bool\n",
    "                Include integer label column in data table. Only relevant for weakly annotated samples. Default is True.\n",
    "            include_attrs: bool\n",
    "                If True, load data from attribute columns in the selection table. Default is False.\n",
    "            attrs: list(str)\n",
    "                Specify the names of the attribute columns that you wish to load data from. \n",
    "                Overwrites include_attrs if specified. If None, all columns will be loaded provided that \n",
    "                include_attrs=True.\n",
    "            data_name: str or list(str) \n",
    "                Name(s) of the data columns. If None is specified, the data column is named 'data', \n",
    "                or 'data0', 'data1', ... if the table contains multiple data columns.\n",
    "            index_cols: str og list(str)\n",
    "                Create indices for the specified columns in the data table to allow for faster queries.\n",
    "                For example, `index_cols=\"filename\"` or `index_cols=[\"filename\", \"label\"]`\n",
    "            mode: str\n",
    "                The mode to open the file. It can be one of the following:\n",
    "                    ’w’: Write; a new file is created (an existing file with the same name would be deleted). \n",
    "                    ’a’: Append; an existing file is opened for reading and writing, and if the file does not exist it is created. This is the default.\n",
    "                    ’r+’: It is similar to ‘a’, but the file must already exist.\n",
    "            tar_file: tarfile \n",
    "                The tar object which contains the tar files. This object is acquired after opening the tar file.\n",
    "            tar_extract_location: str \n",
    "                Path where the audio files will be extracted temporarily and then deleted later.\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    loader = al.AudioSelectionLoader(path=data_dir, selections=selections, channel=channel, \n",
    "        repres=audio_repres, annotations=annotations, include_attrs=include_attrs, attrs=attrs)\n",
    "\n",
    "    writer = AudioWriter(output_file=output_file, max_size=max_size, verbose=verbose, mode=mode,\n",
    "        discard_wrong_shape=discard_wrong_shape, allow_resizing=allow_resizing, \n",
    "        include_source=include_source, include_label=include_label, data_name=data_name, index_cols=index_cols)\n",
    "    \n",
    "    if dataset_name is None: dataset_name = os.path.basename(data_dir)\n",
    "    path_to_dataset = dataset_name if dataset_name.startswith('/') else '/' + dataset_name\n",
    "    \n",
    "    last_processed_filename=''\n",
    "    for i in tqdm(range(loader.num()), disable = not progress_bar):\n",
    "        loader_file_full_path=loader.sel_gen.get_selection(id=i)['filename']\n",
    "        loader_filepath, loader_filename=os.path.split(loader_file_full_path)\n",
    "        extract_foldername=os.path.basename(os.path.dirname(loader_file_full_path))\n",
    "        filename_to_extract=tar_extract_location+extract_foldername+'/'+loader_filename\n",
    "\n",
    "        if os.path.exists(filename_to_extract)==False:\n",
    "            print(\"Not found, extracting . . .\")\n",
    "            print(\"Member:\",extract_foldername+'/'+loader_filename)\n",
    "            print(\"path:\",tar_extract_location)\n",
    "            member_name=extract_foldername+'/'+loader_filename\n",
    "            if(member_name in all_tar_names):\n",
    "                print(\"Member found . . . \", member_name)\n",
    "                tar_file.extract(member=extract_foldername+'/'+loader_filename, path=tar_extract_location)\n",
    "        \n",
    "        if(last_processed_filename!='' and last_processed_filename!=loader_file_full_path):\n",
    "            print(\"removing\", last_processed_filename)\n",
    "            os.remove(last_processed_filename)   \n",
    "\n",
    "        try:\n",
    "            x = next(loader)\n",
    "        except Exception as e:\n",
    "            if(verbose):\n",
    "                print(\"Warning: while loading {0}, Message: {1}\".format(loader_filename, str(e)))\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            writer.write(x=x, path=path_to_dataset, name='data')\n",
    "        except Exception as e:\n",
    "            if(verbose):\n",
    "                print(\"Warning: while writing {0}, Message: {1}\".format(loader_filename, str(e)))\n",
    "\n",
    "        last_processed_filename=loader_file_full_path\n",
    "    \n",
    "    try:\n",
    "        os.remove(last_processed_filename) \n",
    "        os.rmdir(loader_filepath)\n",
    "    except OSError as e:\n",
    "        print(\"Error while deleting audio folder location: %s : %s\" % (loader_filepath, e.strerror))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database for each class label\n",
    "create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='kw', selections=kw_sel_annot_df,\n",
    "                                audio_repres=spec_cfg, tar_file=tar)\n",
    "create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='hb', selections=hb_sel_annot_df,\n",
    "                                audio_repres=spec_cfg, tar_file=tar)\n",
    "create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='dolphin', selections=d_sel_annot_df,\n",
    "                                audio_repres=spec_cfg, tar_file=tar)\n",
    "create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='other', selections=other_sel_annot_df,\n",
    "                                audio_repres=spec_cfg, tar_file=tar)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
