{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 09:36:37.961190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-13 09:36:37.964899: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-13 09:36:37.965116: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cdr767.int.cedar.computecanada.ca): /proc/driver/nvidia/version does not exist\n",
      "2022-01-13 09:36:37.968673: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/sadman/ketos_dl/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from ketos.data_handling import selection_table as sl\n",
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.data_handling.database_interface import AudioWriter, create_database\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "import ketos.audio.audio_loader as al\n",
    "from ketos.audio.spectrogram import MagSpectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec_cfg: {'duration': 5.0, 'rate': 10000, 'window': 0.051, 'step': 0.01955, 'freq_min': 0, 'freq_max': 6000, 'window_func': 'hamming', 'normalize_wav': True, 'type': 'MagSpectrogram', 'transforms': [{'name': 'reduce_tonal_noise'}, {'name': 'normalize', 'mean': 0.0, 'std': 1.0}]}\n"
     ]
    }
   ],
   "source": [
    "# root_path='/home/sadmans/KW_detector_multiclass/' # Orca-VM\n",
    "# root_path='/home/sadman/KW_detector_multiclass/' # DL Training pc\n",
    "# root_path = '/home/sadman/projects/ctb-ruthjoy/sadman/Projects/KW_detector_multiclass/'  # Cedar\n",
    "root_path='../../' \n",
    "\n",
    "# Load spectrogram config file\n",
    "spec_cfg = load_audio_representation(root_path+'code/create_db/spec_config.json', name=\"spectrogram\")\n",
    "print(\"spec_cfg:\", spec_cfg)\n",
    "\n",
    "path_dict = {'train_annot': root_path+'annotations/train/',\n",
    "             'test_annot': root_path+'annotations/test/',\n",
    "             'audio_data_dir': '/data/audio',\n",
    "             'database_save_filename': root_path+'saved_database/test_ds_multiclass_original.h5'\n",
    "             }\n",
    "\n",
    "select_step, select_min_overlap = spec_cfg['duration'], 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jasco_roberts_kw_db():\n",
    "    \"\"\" Load train true positive (KW), and false positive (Non-KW) annotations.\n",
    "        Preprocess the annotation by adding appropriate path.\n",
    "        Finally, create and save hdf5 file\n",
    "    \"\"\"\n",
    "\n",
    "    tp = pd.read_csv(path_dict['train_annot']+\"JASCO_tp_train.csv\")\n",
    "    fp = pd.read_csv(path_dict['train_annot']+\"JASCO_fp_train.csv\")\n",
    "\n",
    "    # Read test files (detailed annotations) for the Robert's bank and boundary pass locations.\n",
    "    jasco_test_files_roberts = pd.read_csv(path_dict['test_annot']+\"jasco_roberts_bank_annot.csv\", sep=',')\n",
    "    jasco_test_files_roberts[\"filename\"] = jasco_test_files_roberts[\"filename\"]\n",
    "    jasco_test_files_boundary = pd.read_csv(path_dict['test_annot']+\"jasco_boundary_pass_annot.csv\", sep=',')\n",
    "    jasco_test_files_boundary[\"filename\"] = jasco_test_files_boundary[\"filename\"]\n",
    "\n",
    "    # Compile a list of filenames present in the test files. These will be used to make sure test data is not included in the pre-processed training database.\n",
    "    all_jasco_test_files = np.concatenate([jasco_test_files_roberts.loc[:, \"filename\"].unique(),\n",
    "                                           jasco_test_files_boundary.loc[:, \"filename\"].unique()])\n",
    "\n",
    "    tp['date_time'] = pd.to_datetime(tp['date_time'], infer_datetime_format=True)\n",
    "    fp['date_time'] = pd.to_datetime(fp['date_time'], infer_datetime_format=True)\n",
    "\n",
    "    # Compile a list of all filescontaining validated detections at the presence/absence level.\n",
    "    all_jasco_files = pd.concat([tp.loc[:, (\"filename\", \"date_time\")].groupby(\"filename\").first().reset_index(),\n",
    "                                fp.loc[:, (\"filename\", \"date_time\")].groupby(\"filename\").first().reset_index()])\n",
    "\n",
    "    # Determine the indices for those file that will be reserved for testing\n",
    "    indices_used_for_test = all_jasco_files.index[all_jasco_files.filename.isin(all_jasco_test_files)].to_list()\n",
    "    # Get the dates for those files that will be reserved for testing\n",
    "    dates_used_for_test = all_jasco_files.iloc[indices_used_for_test].date_time.to_list()\n",
    "\n",
    "    # Add a buffer of one day befor and one day after each date that contained data reserved for testing.\n",
    "    # This ensures there's at least 1 day between any clip used for testing and data that is used for training.\n",
    "    days_used_for_test = set([d.date() for d in dates_used_for_test])\n",
    "    days_used_for_test_buffer = days_used_for_test.union({d - datetime.timedelta(days=1) for d in days_used_for_test})\n",
    "    days_used_for_test_buffer = days_used_for_test_buffer.union({d + datetime.timedelta(days=1) for d in days_used_for_test})\n",
    "\n",
    "    # Exclude any test dates (with the 1 day buffer) from the data vailable for training.\n",
    "    tp_exclude_test = tp[tp.apply(func=lambda r:r['date_time'].date() not in days_used_for_test_buffer, axis=1)]\n",
    "    fp_exclude_test = fp[fp.apply(func=lambda r:r['date_time'].date() not in days_used_for_test_buffer, axis=1)]\n",
    "\n",
    "    # Standardize the annotation tables to the ketos format\n",
    "    std_annot_train_tp = sl.standardize(table=tp_exclude_test, signal_labels=[1],  trim_table=True)\n",
    "    std_annot_train_fp = sl.standardize(table=fp_exclude_test, signal_labels=[1], backgr_labels=[0], trim_table=True)\n",
    "\n",
    "    print(\"std_annot_train_tp, std_annot_train_fp: \", len(std_annot_train_tp), len(std_annot_train_fp))\n",
    "\n",
    "    # Create 5s clips\n",
    "    std_annot_train_tp = sl.select(annotations=std_annot_train_tp,\n",
    "                                   length=spec_cfg['duration'], step=select_step, \n",
    "                                   min_overlap=select_min_overlap, center=False)\n",
    "    std_annot_train_fp = sl.select(annotations=std_annot_train_fp,\n",
    "                                   length=spec_cfg['duration'], step=select_step, \n",
    "                                   min_overlap=select_min_overlap, center=False)  # Augmented with time-shifts\n",
    "\n",
    "    print(\"std_annot_train_tp, std_annot_train_fp: \", len(std_annot_train_tp), len(std_annot_train_fp))\n",
    "\n",
    "    # Create the database with positive and negative datasets\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                    dataset_name='kw', selections=std_annot_train_tp,\n",
    "                    audio_repres=spec_cfg)\n",
    "\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                    dataset_name='other', selections=std_annot_train_fp,\n",
    "                    audio_repres=spec_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative_samples(annot_df, map_to_ketos_annot_std, add_ratio):\n",
    "    \"\"\" Add negative samples from randomly selected files from the annotation dataframe\n",
    "     \n",
    "        Args:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table.\n",
    "\n",
    "        Returns:\n",
    "            annot_df: pandas DataFrame\n",
    "                Annotation table after pre-processing\n",
    "            map_to_ketos_annot_std: dict\n",
    "                Dictionary of dataframe's column name mapping to rename\n",
    "            add_ratio: float\n",
    "                Percentage of file to be used from the annotation dataframe for extracting negative samples\n",
    "\n",
    "    \"\"\"\n",
    "    # Change the location of 'target_wav_location' to choose random neg samples from that location\n",
    "    list_of_wav_files=annot_df['filename'].unique()\n",
    "    print(\"list_of_wav_files:\", len(list_of_wav_files))\n",
    "\n",
    "    # Define the ratio of files to be taken from the folder\n",
    "    total_files=int(len(list_of_wav_files)*add_ratio)\n",
    "    print(\"total_files:\", total_files)\n",
    "\n",
    "    # Now, generate list of unique file indices\n",
    "    file_indices_random = random.sample(range(0, len(list_of_wav_files)), total_files)\n",
    "\n",
    "    total_wav_parsed = 0\n",
    "    total_number_of_negative_samples=0\n",
    "    for file_index in file_indices_random:\n",
    "        target_wav_filename=list_of_wav_files[file_index]\n",
    "        target_matched_annot_df = annot_df[annot_df['filename'].str.find(os.path.basename(target_wav_filename)) != -1]\n",
    "        \n",
    "        if(len(target_matched_annot_df)!=0):\n",
    "            total_time_of_file = librosa.get_duration(filename=target_wav_filename)\n",
    "            target_files_with_len = pd.DataFrame({'filename':[target_wav_filename], \n",
    "                                                'duration':[total_time_of_file]})\n",
    "\n",
    "            #Standardize annotation table format\n",
    "            annot, label_dict = sl.standardize(target_matched_annot_df, mapper=map_to_ketos_annot_std, return_label_dict=True, trim_table=True)\n",
    "\n",
    "            sel = sl.select_by_segmenting(files=target_files_with_len, \n",
    "                                    length=spec_cfg['duration'], \n",
    "                                    annotations=annot, \n",
    "                                    step=spec_cfg['duration'],\n",
    "                                    keep_only_empty=True) \n",
    "\n",
    "            # Check if there is any BH class in the selection table\n",
    "            sel_only_0=sel.loc[sel['label']==0] \n",
    "            \n",
    "            create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                            dataset_name='other', selections=sel_only_0,\n",
    "                                            audio_repres=spec_cfg)\n",
    "\n",
    "            total_wav_parsed+=1\n",
    "            total_number_of_negative_samples+=len(sel_only_0)\n",
    "    \n",
    "    print(\"Total audio files processed: \", total_wav_parsed)\n",
    "    print(\"Total negative samples added: \", total_number_of_negative_samples)\n",
    "    \n",
    "    # ============== Add Negative/Other class samples ===============\n",
    "    annot_df=pd.read_csv(path_dict['train_annot']+\"onc_barkley_canyon_train_multiclass.csv\", sep=',')\n",
    "    map_to_ketos_annot_std={'sound_id_species': 'label'}\n",
    "    add_negative_samples(annot_df, map_to_ketos_annot_std, add_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onc_kw_hb_d_db():\n",
    "    dataset_name='onc_barkley_canyon'\n",
    "    annot_df=pd.read_csv(path_dict['train_annot']+\"onc_barkley_canyon_train_multiclass.csv\", sep=',')\n",
    "\n",
    "    map_to_ketos_annot_std ={'sound_id_species': 'label'} \n",
    "    std_annot_df, label_dict=sl.standardize(table=annot_df,  mapper=map_to_ketos_annot_std, signal_labels=['KW', 'HB', 'D'], trim_table=False, return_label_dict=True)\n",
    "    print(\"label_dict:\", label_dict) # {'KW': 1, 'HB': 2, 'D': 3}\n",
    "    \n",
    "    print(\"std_annot_df:\", len(std_annot_df))\n",
    "    sel_annot_df = sl.select(annotations=std_annot_df, length=spec_cfg['duration'], step=select_step, min_overlap=select_min_overlap, center=False)\n",
    "    print(\"sel_annot_df:\", len(sel_annot_df))\n",
    "\n",
    "    kw_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=1, start=None, end=None)\n",
    "    hb_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=2, start=None, end=None)\n",
    "    d_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=3, start=None, end=None)\n",
    "    \n",
    "    print(len(kw_sel_annot_df), len(hb_sel_annot_df), len(d_sel_annot_df))\n",
    "    \n",
    "    print(\"Adding positive samples from \", dataset_name)\n",
    "\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='kw', selections=kw_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='hb', selections=hb_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='dolphin', selections=d_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files=['/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151015T225849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151015T235849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151016T002849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151016T005849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151024T195849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151024T205849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151024T211349Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151027T235849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151110T065849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151110T071349Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151110T072849Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151110T074349Z.wav',\n",
    " '/data/HALLO/JASCO-Malahat-VFPA/audio/SHMALAHAT-STN4-2015FALL/AMAR439.9.20151114T021349Z.wav']\n",
    "\n",
    "def create_jasco_malahat_vfpa_kw_hb_other_db():\n",
    "    dataset_name='jasco_malahat_vfpa'\n",
    "    annot_df=pd.read_csv(path_dict['train_annot']+\"jasco_malahat_vfpa_train_multiclass.csv\", sep=',')\n",
    "\n",
    "    # ======== Removing missing files ========\n",
    "    # annot_df = annot_df[annot_df.filename in missing_files]\n",
    "    # ======== Removing missing files ========\n",
    "\n",
    "    std_annot_df, label_dict=sl.standardize(table=annot_df, signal_labels=['kw', 'hb', 'other'], trim_table=False, return_label_dict=True)\n",
    "    print(\"label_dict:\", label_dict)\n",
    "    # {'kw': 1, 'hb': 2, 'other': 3}\n",
    "\n",
    "    sel_annot_df = sl.select(annotations=std_annot_df, length=spec_cfg['duration'], step=select_step, min_overlap=select_min_overlap, center=False)\n",
    "    print(\"sel_annot_df:\", len(sel_annot_df))\n",
    "    kw_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=1, start=None, end=None)\n",
    "    hb_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=2, start=None, end=None)\n",
    "    other_sel_annot_df=sl.query(sel_annot_df, annotations=None, filename=None, label=3, start=None, end=None)\n",
    "\n",
    "    print(len(kw_sel_annot_df), len(hb_sel_annot_df), len(other_sel_annot_df))\n",
    "\n",
    "    print(\"Adding positive samples from \", dataset_name)\n",
    "\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='kw', selections=kw_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='hb', selections=hb_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)\n",
    "    create_database(output_file=path_dict['database_save_filename'], data_dir=path_dict['audio_data_dir'],\n",
    "                                dataset_name='other', selections=other_sel_annot_df,\n",
    "                                audio_repres=spec_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jasco_roberts_kw_db()\n",
    "create_onc_kw_hb_d_db()\n",
    "create_jasco_malahat_vfpa_kw_hb_other_db()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b96e40ceac2b3ccede4ea89bd6ac2d6ffadd65bc309d45cf8a3ec91823663213"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
